# -*- coding: utf-8 -*-
"""Deep_Learning_tensor_flow_sequential.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10EU7OrDHPJYWuroyY_5ShMHGPjIpLoXB
"""

!nvidia-smi
# !root path
# 16GB-we can use
# fashion mnist dataset
# 10type of categories 70000 images

import tensorflow as tf
# package-->neural network for training another eg: pytorch

mnist=tf.keras.datasets.fashion_mnist

(training_images,training_labels),(testing_images,testing_labels)=mnist.load_data()

print("no of training images:",len(training_images))
print("no of testing images:",len(testing_images))

import matplotlib.pyplot as plt
plt.imshow(training_images[0])
# images are in BGR format
# 28*28 pixel

# Normalisation
# pixel values are normalised
training_images=training_images/255.0
testing_images=testing_images/255.0

# model
# sequential==forward+backward
# define different layers inside sequential
# relu activation=max(0,x)
# only nodes triggers only values>0 checks whether values are greater than 0(graph in google)
# nodes triggers using relu activation function
model=tf.keras.models.Sequential([
    tf.keras.layers.Flatten(),# creating first layer(input layer)
    tf.keras.layers.Dense(units=128,activation=tf.nn.relu),# create interconnecting layers ,1 hidden leyer,units=number of nodes,each nodes perform summation,activation function(renu),nn=neural network
    tf.keras.layers.Dense(units=10,activation=tf.nn.softmax) #output layer,  10 categories=no. of nodes,softmax=return max value out of accuracy of 10 categories
])

# loss function==for backward propagation

# MSE-Mean Squared Error

#     regression task

# MAE-Mean Absolute error
  #  --regression task

# Binary cross entropy
#          -binary classification


# categorical cross entropy
  #  ---multiclass classification
  #  ---one hot encoded (true class labels)
  #  --here we cannot use in this case we use labels which is a number
  # eg:trouser,shirt,sneaker(true class labels)


# sparse categorical cross entropy
  # ----multi class classification
  # ----not one hot encoded(integer class labels)
  # 0,1,2(integer class labels

'''
    Optimizers
    **************
    Adam(most efficient)
    gradient descent
    stochastic gradient descent
    adagrad
'''

model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

'''
for each epochs:
  if accuracy increases and loss decreases:
    model=sucess
    else:
    model=failed
'''

model.fit(training_images,training_labels,epochs=20)

test_loss,test_acc=model.evaluate(testing_images,testing_labels)

print("testing accuracy:",test_acc)

print("testing_loss:",test_loss)

model.save("mnist_model.h5")